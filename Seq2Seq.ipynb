{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-08T19:30:05.892374Z",
     "start_time": "2024-07-08T19:29:59.078679Z"
    }
   },
   "source": [
    "import unicodedata\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import unicodedata\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "import random\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T19:30:10.003942Z",
     "start_time": "2024-07-08T19:30:05.895904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SOS_TOKEN = 0\n",
    "EOS_TOKEN = 1\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self,name):\n",
    "        self.name = name\n",
    "        self.word2index ={}\n",
    "        self.word2count ={}\n",
    "        self.index2word = {\n",
    "            0:\"SOS\", 1:\"EOS\"\n",
    "        }\n",
    "        self.n_words = 2 # number of words\n",
    "        \n",
    "    def addSentence(self,sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "        \n",
    "    def addWord(self,word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words +=1 \n",
    "        else:\n",
    "            self.word2count[word] +=1\n",
    "            \n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize(\"NFD\",s) if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    \n",
    "    return s\n",
    "\n",
    "\n",
    "def readLangs(lang1,lang2,reverse=False):\n",
    "    print(\"Reading lines ... \")\n",
    "    \n",
    "    lines = open(\"./%s-%s.txt\" % (lang1,lang2), encoding = 'utf-8').read().strip().split('\\n')\n",
    "    \n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs ]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    \n",
    "    return input_lang,output_lang,pairs\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' '))<MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(lang1,lang2,reverse=False):\n",
    "    input_lang,output_lang,pairs = readLangs(lang1,lang2,reverse)\n",
    "    print(\"Reading %s sentence pairs \", len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\", len(pairs))\n",
    "    print(\"Counting words\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "        \n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ],
   "id": "e68d997817e3a846",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines ... \n",
      "Reading %s sentence pairs  135842\n",
      "Trimmed to %s sentence pairs 10599\n",
      "Counting words\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803\n",
      "['elle a peur de retomber malade .', 'she is afraid of falling ill again .']\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T19:31:52.720060Z",
     "start_time": "2024-07-08T19:31:52.702900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Encoder\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,input_size,hidden_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embeds = nn.Embedding(input_size,hidden_dim)\n",
    "        self.gru = nn.GRU(hidden_dim,hidden_dim)\n",
    "        \n",
    "    def forward(self,x,hidden):\n",
    "        embeds = self.embeds(x).view(1,1,-1)\n",
    "        output,hidden = self.gru(embeds,hidden)\n",
    "        return output,hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1,1,self.hidden_dim,device=device)\n",
    "    \n",
    "    \n",
    "## Decoder\n",
    "\n",
    "class AttnDecoder(nn.Module):\n",
    "    def __init__(self,hidden_dim,output_size,max_len=MAX_LENGTH):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_size = output_size\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        self.embeds = nn.Embedding(self.output_size,self.hidden_dim)\n",
    "        self.attn_matrix = nn.Parameter(data = torch.ones((self.hidden_dim,self.hidden_dim)),requires_grad=True)\n",
    "        self.gru = nn.GRU(self.hidden_dim*2,self.hidden_dim)\n",
    "        self.out = nn.Linear(self.hidden_dim,self.output_size)\n",
    "        \n",
    "    def forward(self,x,hidden,encoder_outputs):\n",
    "        embeds = self.embeds(x).view(1,1,-1)\n",
    "        attn_weights = torch.matmul(torch.matmul(hidden[0],self.attn_matrix),torch.transpose(encoder_outputs,0,1))\n",
    "        # 1 x max_len\n",
    "        attn_weights = F.softmax(attn_weights,dim=1)\n",
    "        \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1),encoder_outputs.view(1,-1,self.hidden_dim))\n",
    "        \n",
    "        input_gru = torch.cat((attn_applied[0],embeds[0]),dim=1)\n",
    "        \n",
    "        output,hidden = self.gru(input_gru.unsqueeze(0),hidden)\n",
    "        output = F.log_softmax(self.out(output[0]),dim=1)\n",
    "        \n",
    "        return output,hidden,attn_weights"
   ],
   "id": "3239a947863ba3f5",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T19:31:53.382984Z",
     "start_time": "2024-07-08T19:31:53.373639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def indexexFromSentece(lang,sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang,sentence):\n",
    "    indexes = indexexFromSentece(lang,sentence)\n",
    "    indexes.append(EOS_TOKEN)\n",
    "    return torch.tensor(indexes,dtype=torch.long,device=device).view(-1,1)\n",
    "\n",
    "def tensorFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang,pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang,pair[1])\n",
    "    return (input_tensor,target_tensor)\n"
   ],
   "id": "3513e4f1108c7b35",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T19:49:56.504882Z",
     "start_time": "2024-07-08T19:44:10.823741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hidden_size = 256\n",
    "teacher_forcing_ratio = 0.5\n",
    "max_length = MAX_LENGTH\n",
    "n_iters = 50000\n",
    "n_epochs = 1\n",
    "lr = 0.001\n",
    "device = \"cpu\"\n",
    "\n",
    "\n",
    "encoder = Encoder(input_size=input_lang.n_words,hidden_dim=hidden_size).to(device)\n",
    "\n",
    "decoder = AttnDecoder(hidden_dim=hidden_size,output_size=output_lang.n_words,max_len=max_length).to(device)\n",
    "\n",
    "encoder_opt = torch.optim.Adam(encoder.parameters(),lr=lr)\n",
    "decoder_opt = torch.optim.Adam(decoder.parameters(),lr=lr)\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "training_pairs = [tensorFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "\n",
    "for epoch in range(n_epochs+1):\n",
    "    for iter in range(1,n_iters+1):\n",
    "        \n",
    "        training_pair = training_pairs[iter-1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        \n",
    "        #encoder\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        \n",
    "        input_len = input_tensor.size(0)\n",
    "        target_len = target_tensor.size(0)\n",
    "        \n",
    "        encoder_outputs = torch.zeros(max_length,encoder.hidden_dim,device=device)\n",
    "        \n",
    "        loss = 0\n",
    "        \n",
    "        for ei in range(input_len):\n",
    "            encoder_output,encoder_hidden = encoder(input_tensor[ei],encoder_hidden)\n",
    "            encoder_outputs[ei] = encoder_output[0,0]\n",
    "            \n",
    "        #decoder\n",
    "        output_sentence = [output_lang.index2word[t.item()] for t in target_tensor]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_TOKEN]],device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        use_teacher_forcing = True if random.random()< teacher_forcing_ratio else False\n",
    "        \n",
    "        decoded_sentence = []\n",
    "        if use_teacher_forcing:\n",
    "            for di in range(target_len):\n",
    "                decoder_output,decoder_hidden,decoder_att = decoder(decoder_input,decoder_hidden,encoder_outputs)\n",
    "                \n",
    "                topv,topi = decoder_output.topk(1)\n",
    "                decoded_sentence.append(output_lang.index2word[topi.item()])\n",
    "                \n",
    "                loss += loss_fn(decoder_output,target_tensor[di])\n",
    "                decoder_input = target_tensor[di]\n",
    "            \n",
    "        else:\n",
    "            for di in range(target_len):\n",
    "                decoder_output,decoder_hidden,decoder_att = decoder(decoder_input,decoder_hidden,encoder_outputs)\n",
    "                \n",
    "                topv,topi = decoder_output.topk(1)\n",
    "                decoded_sentence.append(output_lang.index2word[topi.item()])\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "                \n",
    "                loss+= loss_fn(decoder_output,target_tensor[di])\n",
    "                if decoder_input.item() == EOS_TOKEN:\n",
    "                    break\n",
    "                    \n",
    "        encoder_opt.zero_grad()\n",
    "        decoder_opt.zero_grad()\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        encoder_opt.step()\n",
    "        decoder_opt.step()\n",
    "    \n",
    "        #bleu_score = sentence_bleu([output_sentence[:-1]],decoded_sentence[:-1])\n",
    "    \n",
    "        if iter%500 == 0:\n",
    "              print('epoch: {}, iter: {}, loss: {:.6f}, '.format(epoch, iter, loss.item() / target_len))"
   ],
   "id": "ca26d278b0050378",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 500, loss: 2.819708, \n",
      "epoch: 0, iter: 1000, loss: 1.415829, \n",
      "epoch: 0, iter: 1500, loss: 1.989942, \n",
      "epoch: 0, iter: 2000, loss: 3.183518, \n",
      "epoch: 0, iter: 2500, loss: 1.210539, \n",
      "epoch: 0, iter: 3000, loss: 3.101019, \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[34], line 75\u001B[0m\n\u001B[0;32m     72\u001B[0m encoder_opt\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     73\u001B[0m decoder_opt\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 75\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     77\u001B[0m encoder_opt\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     78\u001B[0m decoder_opt\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\_tensor.py:525\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    517\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    518\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    523\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    524\u001B[0m     )\n\u001B[1;32m--> 525\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[0;32m    526\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[0;32m    527\u001B[0m )\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    262\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    266\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 267\u001B[0m _engine_run_backward(\n\u001B[0;32m    268\u001B[0m     tensors,\n\u001B[0;32m    269\u001B[0m     grad_tensors_,\n\u001B[0;32m    270\u001B[0m     retain_graph,\n\u001B[0;32m    271\u001B[0m     create_graph,\n\u001B[0;32m    272\u001B[0m     inputs,\n\u001B[0;32m    273\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    274\u001B[0m     accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    275\u001B[0m )\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    742\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    743\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    745\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    746\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    748\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": " ",
   "id": "fd570a449c3a9d1a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
